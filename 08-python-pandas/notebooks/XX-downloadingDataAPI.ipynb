{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data with APIs\n",
    "\n",
    "* Contact: Lachlan Deer, @ldeer [econgit], @lachlandeer [github]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import BLS Area Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bls_area_codes = pd.read_csv('data/bls_area_codes.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how does this data look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type_code</th>\n",
       "      <th>area_code</th>\n",
       "      <th>area_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>ST0100000000000</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>ST0200000000000</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>ST0400000000000</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>ST0500000000000</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>ST0600000000000</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  area_type_code        area_code   area_text\n",
       "0              A  ST0100000000000     Alabama\n",
       "1              A  ST0200000000000      Alaska\n",
       "2              A  ST0400000000000     Arizona\n",
       "3              A  ST0500000000000    Arkansas\n",
       "4              A  ST0600000000000  California"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_area_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests `area_type_code==A` should subset all the states. This is indeed true, if we look at the help files of the BLS website https://www.bls.gov/help/def/la.htm\n",
    "\n",
    "Let's extract only the state codes that we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = bls_area_codes.query('area_type_code == \"A\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check that we have a data frame of the expected shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Series IDs\n",
    "\n",
    "To extract data from the BLS API we have to pass the an ID for the series that we want to get. To start - take a look here:https://www.bls.gov/help/hlpforma.htm#LA to get a sense of how we need to assemble a series ID.\n",
    "\n",
    "We learn that:\n",
    "* `LA` denotes the local area unemployment data\n",
    "* `U` denotes unadjusted data, while `S` denotes seasonally unadjusted\n",
    "* We then have to pass an area code, which comprises\n",
    "    * the area codes from the BLS file above actually completely specifies the area code we need\n",
    "* Different employment data have IDs we need to specify\n",
    "    * 03 is unemployment rate\t\n",
    "    * 04 is unemployment\t\n",
    "    * 05 is employment\t\n",
    "    * 06 is labor force\t\n",
    "\n",
    "So if we want the Unemployment rate for California, the code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUST060000000000003\n"
     ]
    }
   ],
   "source": [
    "CA_unemp = 'LAU' + 'ST0600000000000' + '03'\n",
    "print(CA_unemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the API Call - Downloading a Single Series\n",
    "\n",
    "now we need to set up an call to the BLS API to return the data to us. If we loosely follow their instructions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an API key to make the amount of calls we will make today. Register here: https://data.bls.gov/registrationEngine/.\n",
    "\n",
    "Set up a python file called `api_key.py` that contains one variable BLS_KEY that contains our private key. Make sure this file is ignored in any version control software so you don't share it with the world "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load BEA API key\n",
    "from api_key import BLS_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up api call\n",
    "headers = {'Content-type': 'application/json'}\n",
    "data_request = json.dumps({\"seriesid\":[ CA_unemp ],\n",
    "                           \"startyear\": \"2000\", \n",
    "                           \"endyear\": \"2016\",\n",
    "                           \"registrationkey\": BLS_KEY})\n",
    "\n",
    "# make the call\n",
    "payload = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', \n",
    "                        data=data_request, headers=headers)\n",
    "# get the data\n",
    "json_data = json.loads(payload.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, thats a little ugly but has all the data that we need. Let's find a way to get that into a nice table format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = [\"state\",\"year\",\"period\",\"value\",\"footnotes\"]\n",
    "data   = json_data['Results']['series']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now getting stuff out of data is a little tricky because of how its returned, its a list of size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUST060000000000003\n"
     ]
    }
   ],
   "source": [
    "seriesID = data[0]['seriesID']\n",
    "print(seriesID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will put the data in a csv file with the following destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = 'data/bls-employment-state/' + seriesID + '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row of the data, we want the State Name, plus the fields specified above as columns.\n",
    "To make the code readily extendable to extracting multiple series, we will get the state code from the `seriesID` and look up the corresponding State Name from the BLS area code data set we have in the session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California\n"
     ]
    }
   ],
   "source": [
    "iState = seriesID[3:-2]\n",
    "state = states.query('area_code == @iState')['area_text'] \\\n",
    "        .reset_index(drop=True).get_value(0, 'area_text')\n",
    "\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to write the data to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for series in json_data['Results']['series']:\n",
    "    with open(outfile, 'w') as iFile:\n",
    "                writer = csv.writer(iFile)\n",
    "                writer.writerow(fields)\n",
    "\n",
    "                for item in series['data']:\n",
    "                    year = item['year']\n",
    "                    period = item['period']\n",
    "                    value = item['value']\n",
    "                    footnotes=\"\"\n",
    "                    for footnote in item['footnotes']:\n",
    "                        if footnote:\n",
    "                            footnotes = footnotes + footnote['text'] + ','\n",
    "\n",
    "                    if 'M01' <= period <= 'M12':\n",
    "                        writer.writerow([state,year,period,value,footnotes[0:-1]])\n",
    "\n",
    "    iFile.close()  # good idea to close if you're done with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did that work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/bls-employment-state/LAUST060000000000003.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob(\"data/bls-employment-state/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now lets try and get a bunch of data using what we just learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the API Call - Downloading Multiple Series\n",
    "\n",
    "Now we want to get the unemployment rate, qty of unemployed, qty employed and the size of the labor force for each state.\n",
    "\n",
    "One important constraint we will face is that we can only request 50 series in each API call. We will get around this by writing some code that will chunk up our list of series into groups of 50 and send them set by set to the BLS API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling All Series\n",
    "\n",
    "We can use a lambda function to construct lists of all the series of data we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unempRate_codes   = list(states.area_code.apply(lambda x: 'LAU' + x + '03'))\n",
    "unemp_codes       = list(states.area_code.apply(lambda x: 'LAU' + x + '04'))\n",
    "employment_codes  = list(states.area_code.apply(lambda x: 'LAU' + x + '05'))\n",
    "labourForce_codes = list(states.area_code.apply(lambda x: 'LAU' + x + '06'))\n",
    "\n",
    "allSeries = unempRate_codes + unemp_codes + employment_codes + labourForce_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking `allSeries` into groups of 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunkedList = [allSeries[i:i+50] for i in range(0,len(allSeries),50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we have a set of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunkedList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and each list has size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List 0 has 50 series\n",
      "List 1 has 50 series\n",
      "List 2 has 50 series\n",
      "List 3 has 50 series\n",
      "List 4 has 8 series\n"
     ]
    }
   ],
   "source": [
    "for iList in range(0,len(chunkedList)):\n",
    "    print('List', iList, 'has', len(chunkedList[iList]), 'series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making multiple API Calls efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send all these requests to the API, we will:\n",
    "\n",
    "* Loop over each chunk, `iChunk` to\n",
    "    * Build the API call for each chunk\n",
    "    * For each series returned, we will clean the data to create a csv\n",
    "    \n",
    "The way we have set up our code above means we can nest it all inside a loop over the chunks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing chunk: 0\n",
      "Completing chunk: 1\n",
      "Completing chunk: 2\n",
      "Completing chunk: 3\n",
      "Completing chunk: 4\n"
     ]
    }
   ],
   "source": [
    "# Load BEA API key\n",
    "from api_key import BLS_KEY\n",
    "\n",
    "for iChunk in range(0,len(chunkedList)):\n",
    "    data = chunkedList[iChunk]\n",
    "    print('Completing chunk:', iChunk)\n",
    "    \n",
    "    # set up api call\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data_request = json.dumps({\"seriesid\":  data,\n",
    "                               \"startyear\": \"2000\", \n",
    "                               \"endyear\":   \"2016\",\n",
    "                               \"registrationkey\": BLS_KEY})\n",
    "    payload = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', \n",
    "                              data=data_request, headers=headers)\n",
    "    json_data = json.loads(payload.text)\n",
    "    \n",
    "    # save the output to a csv file\n",
    "    fields=[\"state\",\"year\",\"period\",\"value\",\"footnotes\"]\n",
    "\n",
    "    for series in json_data['Results']['series']:\n",
    "\n",
    "        seriesID = series['seriesID']\n",
    "        outfile = 'data/bls-employment-state/' + seriesID + '.csv'\n",
    "\n",
    "        iState = seriesID[3:-2]\n",
    "        state = states.query('area_code == @iState')['area_text'] \\\n",
    "                    .reset_index(drop=True).get_value(0, 'area_text')\n",
    "\n",
    "        with open(outfile, 'w') as iFile:\n",
    "            writer = csv.writer(iFile)\n",
    "            writer.writerow(fields)\n",
    "\n",
    "            for item in series['data']:\n",
    "                year = item['year']\n",
    "                period = item['period']\n",
    "                value = item['value']\n",
    "                footnotes=\"\"\n",
    "                for footnote in item['footnotes']:\n",
    "                    if footnote:\n",
    "                        footnotes = footnotes + footnote['text'] + ','\n",
    "\n",
    "                if 'M01' <= period <= 'M12':\n",
    "                    writer.writerow([state,year,period,value,footnotes[0:-1]])\n",
    "\n",
    "        iFile.close()  # good idea to close if you're done with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout our results quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/bls-employment-state/LAUST010000000000005.csv', 'data/bls-employment-state/LAUST240000000000003.csv', 'data/bls-employment-state/LAUST200000000000006.csv', 'data/bls-employment-state/LAUST470000000000005.csv', 'data/bls-employment-state/LAUST260000000000003.csv', 'data/bls-employment-state/LAUST360000000000004.csv', 'data/bls-employment-state/LAUST480000000000006.csv', 'data/bls-employment-state/LAUST110000000000005.csv', 'data/bls-employment-state/LAUST490000000000004.csv', 'data/bls-employment-state/LAUST130000000000006.csv', 'data/bls-employment-state/LAUST720000000000005.csv', 'data/bls-employment-state/LAUST480000000000005.csv', 'data/bls-employment-state/LAUST170000000000003.csv', 'data/bls-employment-state/LAUST120000000000004.csv', 'data/bls-employment-state/LAUST180000000000004.csv', 'data/bls-employment-state/LAUST060000000000005.csv', 'data/bls-employment-state/LAUST060000000000003.csv', 'data/bls-employment-state/LAUST720000000000003.csv', 'data/bls-employment-state/LAUST410000000000006.csv', 'data/bls-employment-state/LAUST280000000000005.csv', 'data/bls-employment-state/LAUST500000000000006.csv', 'data/bls-employment-state/LAUST400000000000005.csv', 'data/bls-employment-state/LAUST060000000000004.csv', 'data/bls-employment-state/LAUST160000000000003.csv', 'data/bls-employment-state/LAUST260000000000006.csv', 'data/bls-employment-state/LAUST270000000000004.csv', 'data/bls-employment-state/LAUST050000000000006.csv', 'data/bls-employment-state/LAUST040000000000005.csv', 'data/bls-employment-state/LAUST050000000000005.csv', 'data/bls-employment-state/LAUST320000000000006.csv', 'data/bls-employment-state/LAUST540000000000004.csv', 'data/bls-employment-state/LAUST490000000000006.csv', 'data/bls-employment-state/LAUST110000000000004.csv', 'data/bls-employment-state/LAUST550000000000006.csv', 'data/bls-employment-state/LAUST250000000000003.csv', 'data/bls-employment-state/LAUST420000000000003.csv', 'data/bls-employment-state/LAUST160000000000005.csv', 'data/bls-employment-state/LAUST050000000000004.csv', 'data/bls-employment-state/LAUST400000000000006.csv', 'data/bls-employment-state/LAUST210000000000006.csv', 'data/bls-employment-state/LAUST370000000000003.csv', 'data/bls-employment-state/LAUST270000000000005.csv', 'data/bls-employment-state/LAUST100000000000006.csv', 'data/bls-employment-state/LAUST540000000000005.csv', 'data/bls-employment-state/LAUST350000000000004.csv', 'data/bls-employment-state/LAUST390000000000004.csv', 'data/bls-employment-state/LAUST370000000000004.csv', 'data/bls-employment-state/LAUST500000000000005.csv', 'data/bls-employment-state/LAUST360000000000005.csv', 'data/bls-employment-state/LAUST450000000000004.csv', 'data/bls-employment-state/LAUST410000000000005.csv', 'data/bls-employment-state/LAUST150000000000005.csv', 'data/bls-employment-state/LAUST280000000000003.csv', 'data/bls-employment-state/LAUST530000000000005.csv', 'data/bls-employment-state/LAUST210000000000003.csv', 'data/bls-employment-state/LAUST100000000000005.csv', 'data/bls-employment-state/LAUST230000000000005.csv', 'data/bls-employment-state/LAUST290000000000005.csv', 'data/bls-employment-state/LAUST190000000000003.csv', 'data/bls-employment-state/LAUST550000000000005.csv', 'data/bls-employment-state/LAUST250000000000004.csv', 'data/bls-employment-state/LAUST130000000000004.csv', 'data/bls-employment-state/LAUST020000000000005.csv', 'data/bls-employment-state/LAUST240000000000004.csv', 'data/bls-employment-state/LAUST370000000000005.csv', 'data/bls-employment-state/LAUST460000000000005.csv', 'data/bls-employment-state/LAUST400000000000004.csv', 'data/bls-employment-state/LAUST320000000000004.csv', 'data/bls-employment-state/LAUST420000000000004.csv', 'data/bls-employment-state/LAUST400000000000003.csv', 'data/bls-employment-state/LAUST420000000000006.csv', 'data/bls-employment-state/LAUST270000000000003.csv', 'data/bls-employment-state/LAUST510000000000003.csv', 'data/bls-employment-state/LAUST360000000000003.csv', 'data/bls-employment-state/LAUST540000000000003.csv', 'data/bls-employment-state/LAUST560000000000005.csv', 'data/bls-employment-state/LAUST250000000000006.csv', 'data/bls-employment-state/LAUST300000000000004.csv', 'data/bls-employment-state/LAUST280000000000006.csv', 'data/bls-employment-state/LAUST180000000000003.csv', 'data/bls-employment-state/LAUST120000000000006.csv', 'data/bls-employment-state/LAUST320000000000003.csv', 'data/bls-employment-state/LAUST260000000000005.csv', 'data/bls-employment-state/LAUST220000000000003.csv', 'data/bls-employment-state/LAUST370000000000006.csv', 'data/bls-employment-state/LAUST300000000000005.csv', 'data/bls-employment-state/LAUST130000000000005.csv', 'data/bls-employment-state/LAUST510000000000004.csv', 'data/bls-employment-state/LAUST310000000000006.csv', 'data/bls-employment-state/LAUST310000000000003.csv', 'data/bls-employment-state/LAUST440000000000004.csv', 'data/bls-employment-state/LAUST360000000000006.csv', 'data/bls-employment-state/LAUST410000000000003.csv', 'data/bls-employment-state/LAUST180000000000006.csv', 'data/bls-employment-state/LAUST230000000000003.csv', 'data/bls-employment-state/LAUST510000000000005.csv', 'data/bls-employment-state/LAUST080000000000004.csv', 'data/bls-employment-state/LAUST190000000000004.csv', 'data/bls-employment-state/LAUST090000000000004.csv', 'data/bls-employment-state/LAUST410000000000004.csv', 'data/bls-employment-state/LAUST210000000000005.csv', 'data/bls-employment-state/LAUST220000000000005.csv', 'data/bls-employment-state/LAUST720000000000006.csv', 'data/bls-employment-state/LAUST190000000000005.csv', 'data/bls-employment-state/LAUST460000000000004.csv', 'data/bls-employment-state/LAUST290000000000003.csv', 'data/bls-employment-state/LAUST340000000000004.csv', 'data/bls-employment-state/LAUST150000000000004.csv', 'data/bls-employment-state/LAUST350000000000003.csv', 'data/bls-employment-state/LAUST500000000000003.csv', 'data/bls-employment-state/LAUST290000000000004.csv', 'data/bls-employment-state/LAUST150000000000006.csv', 'data/bls-employment-state/LAUST220000000000006.csv', 'data/bls-employment-state/LAUST260000000000004.csv', 'data/bls-employment-state/LAUST500000000000004.csv', 'data/bls-employment-state/LAUST300000000000003.csv', 'data/bls-employment-state/LAUST190000000000006.csv', 'data/bls-employment-state/LAUST130000000000003.csv', 'data/bls-employment-state/LAUST170000000000005.csv', 'data/bls-employment-state/LAUST470000000000003.csv', 'data/bls-employment-state/LAUST510000000000006.csv', 'data/bls-employment-state/LAUST010000000000004.csv', 'data/bls-employment-state/LAUST420000000000005.csv', 'data/bls-employment-state/LAUST200000000000005.csv', 'data/bls-employment-state/LAUST110000000000003.csv', 'data/bls-employment-state/LAUST040000000000003.csv', 'data/bls-employment-state/LAUST180000000000005.csv', 'data/bls-employment-state/LAUST490000000000003.csv', 'data/bls-employment-state/LAUST230000000000006.csv', 'data/bls-employment-state/LAUST120000000000003.csv', 'data/bls-employment-state/LAUST440000000000006.csv', 'data/bls-employment-state/LAUST330000000000003.csv', 'data/bls-employment-state/LAUST090000000000003.csv', 'data/bls-employment-state/LAUST450000000000005.csv', 'data/bls-employment-state/LAUST120000000000005.csv', 'data/bls-employment-state/LAUST040000000000004.csv', 'data/bls-employment-state/LAUST440000000000005.csv', 'data/bls-employment-state/LAUST090000000000006.csv', 'data/bls-employment-state/LAUST340000000000005.csv', 'data/bls-employment-state/LAUST390000000000003.csv', 'data/bls-employment-state/LAUST110000000000006.csv', 'data/bls-employment-state/LAUST100000000000004.csv', 'data/bls-employment-state/LAUST340000000000003.csv', 'data/bls-employment-state/LAUST560000000000003.csv', 'data/bls-employment-state/LAUST560000000000006.csv', 'data/bls-employment-state/LAUST160000000000004.csv', 'data/bls-employment-state/LAUST390000000000005.csv', 'data/bls-employment-state/LAUST240000000000006.csv', 'data/bls-employment-state/LAUST080000000000003.csv', 'data/bls-employment-state/LAUST490000000000005.csv', 'data/bls-employment-state/LAUST530000000000006.csv', 'data/bls-employment-state/LAUST460000000000006.csv', 'data/bls-employment-state/LAUST230000000000004.csv', 'data/bls-employment-state/LAUST080000000000006.csv', 'data/bls-employment-state/LAUST100000000000003.csv', 'data/bls-employment-state/LAUST290000000000006.csv', 'data/bls-employment-state/LAUST050000000000003.csv', 'data/bls-employment-state/LAUST210000000000004.csv', 'data/bls-employment-state/LAUST340000000000006.csv', 'data/bls-employment-state/LAUST460000000000003.csv', 'data/bls-employment-state/LAUST450000000000006.csv', 'data/bls-employment-state/LAUST280000000000004.csv', 'data/bls-employment-state/LAUST240000000000005.csv', 'data/bls-employment-state/LAUST540000000000006.csv', 'data/bls-employment-state/LAUST330000000000004.csv', 'data/bls-employment-state/LAUST470000000000006.csv', 'data/bls-employment-state/LAUST170000000000004.csv', 'data/bls-employment-state/LAUST040000000000006.csv', 'data/bls-employment-state/LAUST150000000000003.csv', 'data/bls-employment-state/LAUST530000000000004.csv', 'data/bls-employment-state/LAUST300000000000006.csv', 'data/bls-employment-state/LAUST330000000000005.csv', 'data/bls-employment-state/LAUST010000000000003.csv', 'data/bls-employment-state/LAUST310000000000004.csv', 'data/bls-employment-state/LAUST320000000000005.csv', 'data/bls-employment-state/LAUST380000000000004.csv', 'data/bls-employment-state/LAUST020000000000006.csv', 'data/bls-employment-state/LAUST080000000000005.csv', 'data/bls-employment-state/LAUST330000000000006.csv', 'data/bls-employment-state/LAUST270000000000006.csv', 'data/bls-employment-state/LAUST450000000000003.csv', 'data/bls-employment-state/LAUST390000000000006.csv', 'data/bls-employment-state/LAUST440000000000003.csv', 'data/bls-employment-state/LAUST530000000000003.csv', 'data/bls-employment-state/LAUST350000000000005.csv', 'data/bls-employment-state/LAUST090000000000005.csv', 'data/bls-employment-state/LAUST170000000000006.csv', 'data/bls-employment-state/LAUST550000000000004.csv', 'data/bls-employment-state/LAUST720000000000004.csv', 'data/bls-employment-state/LAUST060000000000006.csv', 'data/bls-employment-state/LAUST020000000000004.csv', 'data/bls-employment-state/LAUST250000000000005.csv', 'data/bls-employment-state/LAUST560000000000004.csv', 'data/bls-employment-state/LAUST380000000000005.csv', 'data/bls-employment-state/LAUST550000000000003.csv', 'data/bls-employment-state/LAUST480000000000003.csv', 'data/bls-employment-state/LAUST380000000000003.csv', 'data/bls-employment-state/LAUST480000000000004.csv', 'data/bls-employment-state/LAUST160000000000006.csv', 'data/bls-employment-state/LAUST010000000000006.csv', 'data/bls-employment-state/LAUST470000000000004.csv', 'data/bls-employment-state/LAUST350000000000006.csv', 'data/bls-employment-state/LAUST200000000000004.csv', 'data/bls-employment-state/LAUST020000000000003.csv', 'data/bls-employment-state/LAUST200000000000003.csv', 'data/bls-employment-state/LAUST380000000000006.csv', 'data/bls-employment-state/LAUST220000000000004.csv', 'data/bls-employment-state/LAUST310000000000005.csv']\n"
     ]
    }
   ],
   "source": [
    "print(glob.glob(\"data/bls-employment-state/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "Getting data from APIs takes a little getting used to, and the first time you do it for a new API will take time, they don't all look alike and work exactly the same way.\n",
    "\n",
    "*BUT*, using them means the data collection (where possible) becomes reproducible and the output can be made to be neat quite quickly. This is a **big** positive in my book, and reason enough to spend an hour or so learning how to use an API to get data from the data sources that have it available.\n",
    "\n",
    "The remaining notebooks in this directory will use this data, along with some supplementary data to demonstrate how to use the `pandas` library to work efficiently with data sets."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
